{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4Ug7vN6FMLXxlWyzdiFB5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajatKumawat17/Physician_Notetaker/blob/main/Emitrr_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A2VMjb9QioFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9136419-e889-467e-cb14-b168831e6fed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import json\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_md\")\n",
        "    print(\"SpaCy model loaded successfully\")\n",
        "except OSError:\n",
        "    print(\"SpaCy model not found. Installing en_core_web_md...\")\n",
        "    import os\n",
        "    os.system(\"python -m spacy download en_core_web_md\")\n",
        "    nlp = spacy.load(\"en_core_web_md\")\n",
        "    print(\"SpaCy model installed and loaded successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j36XmbFBjA3Y",
        "outputId": "49814326-b4c8-468b-950a-7c3318bee755"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpaCy model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing and Conversation Parser\n"
      ],
      "metadata": {
        "id": "0wXgPMuUPT-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationParser:\n",
        "    \"\"\"\n",
        "    A flexible parser for medical conversations that can handle various formats\n",
        "    \"\"\"\n",
        "    def __init__(self, speaker_patterns=None):\n",
        "        # Default speaker patterns to look for\n",
        "        self.speaker_patterns = speaker_patterns or {\n",
        "            'physician': ['physician:', 'doctor:', 'dr.:', 'provider:', 'physician', 'doctor', 'dr.', 'provider'],\n",
        "            'patient': ['patient:', 'client:', 'pt:', 'patient', 'client', 'pt']\n",
        "        }\n",
        "\n",
        "    def _identify_speakers(self, conversation):\n",
        "        \"\"\"Identify the actual speakers used in this conversation\"\"\"\n",
        "        lines = conversation.strip().split('\\n')\n",
        "        detected_patterns = set()\n",
        "\n",
        "        # Check for any speaker pattern at the beginning of lines\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            for role, patterns in self.speaker_patterns.items():\n",
        "                for pattern in patterns:\n",
        "                    # Check if line starts with pattern (case insensitive)\n",
        "                    if line.lower().startswith(pattern.lower()):\n",
        "                        detected_patterns.add((role, pattern))\n",
        "\n",
        "        return detected_patterns\n",
        "\n",
        "    def _extract_patient_name(self, conversation):\n",
        "        \"\"\"\n",
        "        Extract patient name from the conversation (if possible).\n",
        "        This is a basic example and may need further refinement.\n",
        "        \"\"\"\n",
        "        # For now, assume there's a line like \"Patient: [Patient Name]\"\n",
        "        for line in conversation.split('\\n'):\n",
        "            if line.strip().lower().startswith(\"patient:\"):\n",
        "                try:\n",
        "                    # Attempt to extract name after \"Patient:\"\n",
        "                    name = line.strip().split(\":\", 1)[1].strip()\n",
        "                    # If name contains only letters and spaces, consider it valid\n",
        "                    if re.match(r\"^[a-zA-Z\\s]+$\", name):\n",
        "                        return name\n",
        "                except IndexError:\n",
        "                    pass  # Handle cases where name is not found\n",
        "        return \"Unknown Patient\"  # Default if name extraction fails\n",
        "\n",
        "    def parse(self, conversation):\n",
        "        \"\"\"\n",
        "        Parse the conversation into structured format\n",
        "        \"\"\"\n",
        "        # Identify how speakers are labeled\n",
        "        detected_speakers = self._identify_speakers(conversation)\n",
        "\n",
        "        # If no speakers are detected, try a more flexible approach\n",
        "        if not detected_speakers:\n",
        "            return self._parse_unlabeled_conversation(conversation)\n",
        "\n",
        "        lines = conversation.strip().split('\\n')\n",
        "        physician_statements = []\n",
        "        patient_statements = []\n",
        "        metadata = {}\n",
        "        current_role = None\n",
        "        current_statement = []\n",
        "\n",
        "        # Extract patient name\n",
        "        metadata['patient_name'] = self._extract_patient_name(conversation)\n",
        "\n",
        "        # Parse the conversation line by line\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Check if this line starts a new speaker\n",
        "            new_speaker_found = False\n",
        "            for role, pattern in detected_speakers:\n",
        "                # Create a more flexible pattern match\n",
        "                if line.lower().startswith(pattern.lower()):\n",
        "                    # Save previous statement if there was one\n",
        "                    if current_role and current_statement:\n",
        "                        statement = ' '.join(current_statement)\n",
        "                        if current_role == 'physician':\n",
        "                            physician_statements.append(statement)\n",
        "                        else:\n",
        "                            patient_statements.append(statement)\n",
        "\n",
        "                    # Start new statement\n",
        "                    current_role = role\n",
        "                    # Remove the pattern from the beginning of the line\n",
        "                    # Handle both cases: with and without colon\n",
        "                    if pattern.endswith(':'):\n",
        "                        statement_text = line[len(pattern):].strip()\n",
        "                    else:\n",
        "                        # Check if there's a colon after the pattern\n",
        "                        colon_index = line.find(':', len(pattern))\n",
        "                        if colon_index != -1:\n",
        "                            statement_text = line[colon_index + 1:].strip()\n",
        "                        else:\n",
        "                            statement_text = line[len(pattern):].strip()\n",
        "\n",
        "                    current_statement = [statement_text] if statement_text else []\n",
        "                    new_speaker_found = True\n",
        "                    break\n",
        "\n",
        "            # If no new speaker, continue with current statement\n",
        "            if not new_speaker_found and current_role is not None:\n",
        "                current_statement.append(line)\n",
        "\n",
        "        # Add the last statement\n",
        "        if current_role and current_statement:\n",
        "            statement = ' '.join(current_statement)\n",
        "            if current_role == 'physician':\n",
        "                physician_statements.append(statement)\n",
        "            else:\n",
        "                patient_statements.append(statement)\n",
        "\n",
        "        # Look for physical examination or other special sections\n",
        "        physical_exam = re.search(r'\\[([^]]+(?:examination|exam|assessed|assessment)[^]]*)\\]',\n",
        "                                 conversation, re.IGNORECASE)\n",
        "        if physical_exam:\n",
        "            metadata['physical_examination'] = physical_exam.group(1)\n",
        "\n",
        "        # Debug: If no patient statements found, try fallback method\n",
        "        if not patient_statements:\n",
        "            fallback_result = self._parse_unlabeled_conversation(conversation)\n",
        "            return fallback_result\n",
        "\n",
        "        # Combine into final result\n",
        "        return {\n",
        "            \"physician_statements\": physician_statements,\n",
        "            \"patient_statements\": patient_statements,\n",
        "            \"all_physician_text\": \" \".join(physician_statements),\n",
        "            \"all_patient_text\": \" \".join(patient_statements),\n",
        "            \"metadata\": metadata\n",
        "        }"
      ],
      "metadata": {
        "id": "0GaOz-cAjOJg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medical Entity Recognition System"
      ],
      "metadata": {
        "id": "hspoeOEnPj4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalEntityRecognizer:\n",
        "    \"\"\"\n",
        "    Dynamic medical entity recognition system with expandable categories\n",
        "    \"\"\"\n",
        "    def __init__(self, nlp_model=None):\n",
        "        self.nlp = nlp_model or nlp\n",
        "\n",
        "        # Define medical categories with initial terms that can be expanded\n",
        "        self.medical_categories = {\n",
        "            \"SYMPTOM\": [\n",
        "                \"pain\", \"discomfort\", \"ache\", \"hurt\", \"sore\", \"stiffness\", \"trouble\", \"sleeping\",\n",
        "                \"backache\", \"shocked\", \"swelling\", \"rash\", \"fever\", \"cough\", \"fatigue\", \"nausea\",\n",
        "                \"dizziness\", \"headache\", \"difficulty\", \"shortness of breath\", \"chest pain\",\n",
        "                \"weakness\", \"numbness\", \"tingling\", \"blurry vision\"\n",
        "            ],\n",
        "            \"TREATMENT\": [\n",
        "                \"physiotherapy\", \"therapy\", \"painkillers\", \"medication\", \"advised\", \"sessions\",\n",
        "                \"x-rays\", \"emergency\", \"treatment\", \"surgery\", \"prescription\", \"antibiotics\",\n",
        "                \"procedure\", \"exercise\", \"physical therapy\", \"counseling\", \"radiation\",\n",
        "                \"chemotherapy\", \"medicine\", \"pill\", \"tablet\", \"injection\", \"vaccine\", \"rehabilitation\"\n",
        "            ],\n",
        "            \"DIAGNOSIS\": [\n",
        "                \"whiplash\", \"injury\", \"damage\", \"condition\", \"accident\", \"impact\", \"infection\",\n",
        "                \"disease\", \"syndrome\", \"disorder\", \"fracture\", \"break\", \"sprain\", \"strain\",\n",
        "                \"concussion\", \"diabetes\", \"hypertension\", \"cancer\", \"arthritis\", \"depression\",\n",
        "                \"anxiety\", \"heart disease\", \"inflammation\"\n",
        "            ],\n",
        "            \"PROGNOSIS\": [\n",
        "                \"recovery\", \"improve\", \"better\", \"improving\", \"full recovery\", \"future\", \"sign\",\n",
        "                \"progress\", \"long-term\", \"outlook\", \"prognosis\", \"chance\", \"likely\", \"risk\",\n",
        "                \"survival\", \"recurrence\", \"complication\", \"probability\", \"outcome\", \"expectation\",\n",
        "                \"timeline\", \"chronic\", \"permanent\", \"temporary\", \"healing\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Optional: Load medical terminology from external sources\n",
        "        # self._load_external_terminology()\n",
        "\n",
        "    def _load_external_terminology(self):\n",
        "        \"\"\"\n",
        "        Load additional terminology from external sources like UMLS or SNOMED-CT\n",
        "        (Placeholder function for future expansion)\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def add_terms(self, category, terms):\n",
        "        \"\"\"Allow dynamic addition of terms to categories\"\"\"\n",
        "        if category in self.medical_categories:\n",
        "            self.medical_categories[category].extend(terms)\n",
        "        else:\n",
        "            self.medical_categories[category] = terms\n",
        "\n",
        "    def identify_entities(self, text):\n",
        "        \"\"\"\n",
        "        Use a combination of spaCy NER and rule-based approaches to identify medical entities\n",
        "        \"\"\"\n",
        "        doc = self.nlp(text)\n",
        "        entities = defaultdict(list)\n",
        "\n",
        "        # First pass: Use spaCy's built-in NER\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ in [\"DISEASE\", \"CONDITION\", \"CHEMICAL\", \"MEDICINE\"]:\n",
        "                if ent.text not in entities[\"DIAGNOSIS\"]:\n",
        "                    entities[\"DIAGNOSIS\"].append(ent.text)\n",
        "\n",
        "        # Second pass: Use custom dictionary-based approach with context\n",
        "        for sent in doc.sents:\n",
        "            sent_text = sent.text.lower()\n",
        "            for category, terms in self.medical_categories.items():\n",
        "                for term in terms:\n",
        "                    term_lower = term.lower()\n",
        "                    if term_lower in sent_text:\n",
        "                        # Extract the context around the term (neighboring words)\n",
        "                        pattern = r'(?i)(?:\\w+\\s+){0,3}' + re.escape(term_lower) + r'(?:\\s+\\w+){0,3}'\n",
        "                        matches = re.findall(pattern, sent_text)\n",
        "                        if matches:\n",
        "                            for match in matches:\n",
        "                                # Skip if match is negated (e.g., \"no pain\", \"denied fever\")\n",
        "                                negation_words = [\"no \", \"not \", \"didn't have \", \"doesn't have \", \"deny \", \"denied \"]\n",
        "                                if any(neg in (\" \" + match.lower() + \" \") for neg in negation_words):\n",
        "                                    continue\n",
        "\n",
        "                                # Add if not duplicate\n",
        "                                clean_match = match.strip()\n",
        "                                if clean_match and clean_match not in entities[category]:\n",
        "                                    entities[category].append(clean_match)\n",
        "\n",
        "        # Process and clean the extracted entities\n",
        "        for category in entities:\n",
        "            # Remove duplicates and sort by length (prefer longer, more specific phrases)\n",
        "            entities[category] = sorted(list(set(entities[category])), key=len, reverse=True)\n",
        "\n",
        "            # Remove overlapping terms (e.g., if \"severe headache\" and \"headache\" are both present, keep only \"severe headache\")\n",
        "            final_terms = []\n",
        "            for term in entities[category]:\n",
        "                if not any(term in other_term and term != other_term for other_term in entities[category]):\n",
        "                    final_terms.append(term)\n",
        "            entities[category] = final_terms\n",
        "\n",
        "        return dict(entities)\n"
      ],
      "metadata": {
        "id": "R9ANSP4EkHPo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medical Report Generator"
      ],
      "metadata": {
        "id": "dDXY-VpnPtoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalReportGenerator:\n",
        "    \"\"\"\n",
        "    Dynamic medical report generator that can adapt to different conversation styles\n",
        "    \"\"\"\n",
        "    def __init__(self, entity_recognizer=None):\n",
        "        self.entity_recognizer = entity_recognizer or MedicalEntityRecognizer()\n",
        "\n",
        "    def extract_entities(self, conversation_data):\n",
        "        \"\"\"Extract entities from the conversation data\"\"\"\n",
        "        # Prioritize patient statements for entity extraction\n",
        "        text = conversation_data.get(\"all_patient_text\", \"\")\n",
        "\n",
        "        # Also include physician statements for context\n",
        "        physician_text = conversation_data.get(\"all_physician_text\", \"\")\n",
        "\n",
        "        # Extract entities from patient text\n",
        "        patient_entities = self.entity_recognizer.identify_entities(text)\n",
        "\n",
        "        # Extract additional context from physician text\n",
        "        physician_entities = self.entity_recognizer.identify_entities(physician_text)\n",
        "\n",
        "        # Combine entities, prioritizing patient-reported ones\n",
        "        combined_entities = {}\n",
        "        for category in set(list(patient_entities.keys()) + list(physician_entities.keys())):\n",
        "            patient_category_entities = patient_entities.get(category, [])\n",
        "            physician_category_entities = physician_entities.get(category, [])\n",
        "\n",
        "            # Include unique entities from both sources, prioritizing patient ones\n",
        "            combined_entities[category] = patient_category_entities + [\n",
        "                entity for entity in physician_category_entities\n",
        "                if not any(entity in patient_entity for patient_entity in patient_category_entities)\n",
        "            ]\n",
        "\n",
        "        return combined_entities\n",
        "\n",
        "    def extract_current_status(self, conversation_data):\n",
        "        \"\"\"Extract patient's current status from conversation\"\"\"\n",
        "        patient_text = conversation_data.get(\"all_patient_text\", \"\")\n",
        "\n",
        "        # Look for statements about current condition\n",
        "        status_patterns = [\n",
        "            r\"(?:now|currently|these days|at this point).{1,50}(?:feel|pain|discomfort|symptom)\",\n",
        "            r\"(?:feeling|pain|discomfort|symptom).{1,50}(?:now|currently|these days|at this point)\",\n",
        "            r\"(?:still|occasional|sometimes|intermittent).{1,30}(?:feel|pain|discomfort|symptom)\"\n",
        "        ]\n",
        "\n",
        "        for pattern in status_patterns:\n",
        "            matches = re.findall(pattern, patient_text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                return matches[0].strip()\n",
        "\n",
        "        # Look at most recent patient statement as fallback\n",
        "        statements = conversation_data.get(\"patient_statements\", [])\n",
        "        if statements:\n",
        "            recent_statements = statements[-3:]  # Look at last few statements\n",
        "            for stmt in reversed(recent_statements):\n",
        "                if any(word in stmt.lower() for word in [\"now\", \"current\", \"still\", \"today\", \"feeling\"]):\n",
        "                    return stmt\n",
        "\n",
        "        return \"Current status unclear from conversation\"\n",
        "\n",
        "    def generate_report(self, conversation_data):\n",
        "        \"\"\"\n",
        "        Generate a structured medical report from conversation data\n",
        "        \"\"\"\n",
        "        # Extract entities\n",
        "        entities = self.extract_entities(conversation_data)\n",
        "\n",
        "        # Get patient name\n",
        "        patient_name = conversation_data.get(\"metadata\", {}).get(\"patient_name\", \"Unknown Patient\")\n",
        "\n",
        "        # Extract current status\n",
        "        current_status = self.extract_current_status(conversation_data)\n",
        "\n",
        "        # Extract or infer prognosis\n",
        "        prognosis = \"Prognosis unclear from conversation\"\n",
        "        if \"PROGNOSIS\" in entities and entities[\"PROGNOSIS\"]:\n",
        "            prognosis_terms = entities[\"PROGNOSIS\"]\n",
        "            if any(\"full recovery\" in term for term in prognosis_terms):\n",
        "                prognosis = \"Full recovery expected\"\n",
        "            elif any(\"improve\" in term for term in prognosis_terms):\n",
        "                prognosis = \"Condition expected to improve\"\n",
        "\n",
        "        # Create structured report\n",
        "        report = {\n",
        "            \"Patient_Name\": patient_name,\n",
        "            \"Symptoms\": entities.get(\"SYMPTOM\", []),\n",
        "            \"Diagnosis\": entities.get(\"DIAGNOSIS\", []),\n",
        "            \"Treatment\": entities.get(\"TREATMENT\", []),\n",
        "            \"Current_Status\": current_status,\n",
        "            \"Prognosis\": prognosis\n",
        "        }\n",
        "\n",
        "        return report"
      ],
      "metadata": {
        "id": "KjY4fdYXkMVf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment and Intent Analysis"
      ],
      "metadata": {
        "id": "QD1056B5P3-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalSentimentAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyzes patient sentiment and intent in medical conversations\n",
        "    \"\"\"\n",
        "    def __init__(self, sentiment_model=None):\n",
        "        # Load pre-trained sentiment analysis model\n",
        "        if sentiment_model:\n",
        "            self.sentiment_analyzer = sentiment_model\n",
        "        else:\n",
        "            try:\n",
        "                self.sentiment_analyzer = pipeline(\n",
        "                    \"sentiment-analysis\",\n",
        "                    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "                )\n",
        "            except:\n",
        "                print(\"Warning: Could not load transformer model. Using rule-based analysis only.\")\n",
        "                self.sentiment_analyzer = None\n",
        "\n",
        "        # Dictionaries for sentiment and intent classification\n",
        "        self.sentiment_indicators = {\n",
        "            \"Anxious\": [\n",
        "                \"worried\", \"concern\", \"afraid\", \"scared\", \"fear\", \"anxious\", \"nervous\",\n",
        "                \"uncertain\", \"unsure\", \"stress\", \"scary\", \"terrified\", \"panic\", \"doubt\"\n",
        "            ],\n",
        "            \"Neutral\": [\n",
        "                \"okay\", \"fine\", \"alright\", \"same\", \"unchanged\", \"stable\", \"constant\",\n",
        "                \"regular\", \"normal\", \"usual\", \"routine\", \"moderate\", \"medium\"\n",
        "            ],\n",
        "            \"Reassured\": [\n",
        "                \"better\", \"good\", \"great\", \"improve\", \"relief\", \"confident\", \"happy\",\n",
        "                \"glad\", \"pleased\", \"relieved\", \"hopeful\", \"optimistic\", \"positive\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        self.intent_indicators = {\n",
        "            \"Seeking reassurance\": [\n",
        "                \"will i\", \"hope\", \"worried\", \"concern\", \"?\", \"wonder\", \"curious\",\n",
        "                \"possible\", \"chance\", \"likelihood\", \"probability\", \"risk\", \"fear\"\n",
        "            ],\n",
        "            \"Reporting symptoms\": [\n",
        "                \"pain\", \"hurt\", \"ache\", \"feel\", \"symptom\", \"discomfort\", \"noticed\",\n",
        "                \"experiencing\", \"having\", \"suffered\", \"dealing with\", \"struggling with\"\n",
        "            ],\n",
        "            \"Seeking information\": [\n",
        "                \"what is\", \"how does\", \"when will\", \"why does\", \"could you explain\",\n",
        "                \"tell me about\", \"what causes\", \"how long\", \"what should\", \"how can\"\n",
        "            ],\n",
        "            \"Expressing gratitude\": [\n",
        "                \"thank\", \"appreciate\", \"grateful\", \"glad\", \"helped\", \"useful\",\n",
        "                \"informative\", \"valuable\", \"insightful\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    def analyze_text_segment(self, text):\n",
        "        \"\"\"Analyze a segment of text for sentiment and intent\"\"\"\n",
        "        # Default values\n",
        "        sentiment = \"Neutral\"\n",
        "        intent = \"Sharing information\"\n",
        "        confidence = 0.5\n",
        "\n",
        "        # Use transformer-based model if available\n",
        "        if self.sentiment_analyzer:\n",
        "            try:\n",
        "                result = self.sentiment_analyzer(text)\n",
        "                model_sentiment = result[0]['label']\n",
        "                confidence = result[0]['score']\n",
        "\n",
        "                # Map model sentiment to medical categories\n",
        "                if model_sentiment == 'NEGATIVE' and confidence > 0.7:\n",
        "                    sentiment = \"Anxious\"\n",
        "                elif model_sentiment == 'POSITIVE' and confidence > 0.7:\n",
        "                    sentiment = \"Reassured\"\n",
        "                else:\n",
        "                    sentiment = \"Neutral\"\n",
        "            except Exception as e:\n",
        "                print(f\"Transformer model error: {e}\")\n",
        "\n",
        "        # Rule-based enhancement (regardless of whether model is used)\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Check for sentiment indicators\n",
        "        for sent_type, indicators in self.sentiment_indicators.items():\n",
        "            if any(indicator in text_lower for indicator in indicators):\n",
        "                sentiment = sent_type\n",
        "                break\n",
        "\n",
        "        # Check for intent indicators\n",
        "        for intent_type, indicators in self.intent_indicators.items():\n",
        "            if any(indicator in text_lower for indicator in indicators):\n",
        "                intent = intent_type\n",
        "                break\n",
        "\n",
        "        return {\n",
        "            \"Sentiment\": sentiment,\n",
        "            \"Intent\": intent,\n",
        "            \"Confidence\": confidence\n",
        "        }\n",
        "\n",
        "    def analyze_conversation(self, conversation_data):\n",
        "        \"\"\"\n",
        "        Analyze the entire conversation for sentiment and intent patterns\n",
        "        \"\"\"\n",
        "        patient_statements = conversation_data.get(\"patient_statements\", [])\n",
        "\n",
        "        # If no statements, return default\n",
        "        if not patient_statements:\n",
        "            return {\n",
        "                \"Overall_Sentiment\": \"Neutral\",\n",
        "                \"Primary_Intent\": \"Unknown\",\n",
        "                \"Sentiment_Progression\": \"Insufficient data for progression analysis\",\n",
        "                \"Statement_Analysis\": []\n",
        "            }\n",
        "\n",
        "        # Analyze each statement\n",
        "        statement_results = []\n",
        "        for statement in patient_statements:\n",
        "            if len(statement.strip()) > 5:  # Skip very short statements\n",
        "                result = self.analyze_text_segment(statement)\n",
        "                statement_results.append({\n",
        "                    \"Statement\": statement,\n",
        "                    \"Analysis\": result\n",
        "                })\n",
        "\n",
        "        # Calculate overall sentiment and primary intent\n",
        "        sentiment_counts = {\"Anxious\": 0, \"Neutral\": 0, \"Reassured\": 0}\n",
        "        intent_counts = defaultdict(int)\n",
        "\n",
        "        for result in statement_results:\n",
        "            sentiment = result[\"Analysis\"][\"Sentiment\"]\n",
        "            intent = result[\"Analysis\"][\"Intent\"]\n",
        "\n",
        "            sentiment_counts[sentiment] += 1\n",
        "            intent_counts[intent] += 1\n",
        "\n",
        "        # Get most common sentiment and intent\n",
        "        overall_sentiment = max(sentiment_counts, key=sentiment_counts.get)\n",
        "        primary_intent = max(intent_counts, key=intent_counts.get) if intent_counts else \"Unknown\"\n",
        "\n",
        "        # Initialize sentiment_progression with a default value\n",
        "        sentiment_progression = \"Insufficient data for progression analysis\"\n",
        "\n",
        "        # Look at sentiment progression (beginning, middle, end)\n",
        "        if len(statement_results) >= 3:\n",
        "            beginning = statement_results[0][\"Analysis\"][\"Sentiment\"]\n",
        "            middle_idx = len(statement_results) // 2\n",
        "            middle = statement_results[middle_idx][\"Analysis\"][\"Sentiment\"]\n",
        "            end = statement_results[-1][\"Analysis\"][\"Sentiment\"]\n",
        "\n",
        "            # Check for improvement pattern (anxious to reassured)\n",
        "            if beginning == \"Anxious\" and end == \"Reassured\":\n",
        "                sentiment_progression = \"Improving (Anxious → Reassured)\"\n",
        "            # Check for deterioration pattern\n",
        "            elif beginning == \"Reassured\" and end == \"Anxious\":\n",
        "                sentiment_progression = \"Deteriorating (Reassured → Anxious)\"\n",
        "            else:\n",
        "                sentiment_progression = f\"Stable ({beginning})\"\n",
        "\n",
        "        return {\n",
        "            \"Overall_Sentiment\": overall_sentiment,\n",
        "            \"Primary_Intent\": primary_intent,\n",
        "            \"Sentiment_Progression\": sentiment_progression,\n",
        "            \"Statement_Analysis\": statement_results\n",
        "        }"
      ],
      "metadata": {
        "id": "SUEItfU6kdq3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOAP Note Generator"
      ],
      "metadata": {
        "id": "jlPyCwiQQDzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SOAPNoteGenerator:\n",
        "    \"\"\"\n",
        "    Generates structured SOAP notes from medical conversations\n",
        "    \"\"\"\n",
        "    def __init__(self, entity_recognizer=None):\n",
        "        self.entity_recognizer = entity_recognizer or MedicalEntityRecognizer()\n",
        "\n",
        "    def _extract_chief_complaint(self, entities, conversation_data):\n",
        "        \"\"\"Extract the chief complaint from entities and conversation\"\"\"\n",
        "        # First try to get from symptoms\n",
        "        symptoms = entities.get(\"SYMPTOM\", [])\n",
        "        if symptoms:\n",
        "            return \", \".join(symptoms[:2])  # Top two symptoms\n",
        "\n",
        "        # Fall back to scanning patient statements\n",
        "        patient_statements = conversation_data.get(\"patient_statements\", [])\n",
        "        for statement in patient_statements[:3]:  # Check first few statements\n",
        "            doc = nlp(statement)\n",
        "            for ent in doc.ents:\n",
        "                if ent.label_ in [\"DISEASE\", \"CONDITION\", \"SYMPTOM\"]:\n",
        "                    return ent.text\n",
        "\n",
        "        return \"Unspecified complaint\"\n",
        "\n",
        "    def _extract_history(self, conversation_data, entities):\n",
        "        \"\"\"Extract history of present illness\"\"\"\n",
        "        patient_text = conversation_data.get(\"all_patient_text\", \"\")\n",
        "\n",
        "        # Look for temporal indicators of illness\n",
        "        time_patterns = [\n",
        "            r\"(?:started|began|happened|occurred).{1,50}(?:ago|since|last|past|previous)\",\n",
        "            r\"(?:ago|since|last|past|previous).{1,50}(?:started|began|happened|occurred)\",\n",
        "            r\"(?:for).{1,20}(?:days|weeks|months|years)\",\n",
        "            r\"(?:on|at).{1,30}(?:monday|tuesday|wednesday|thursday|friday|saturday|sunday)\",\n",
        "            r\"(?:january|february|march|april|may|june|july|august|september|october|november|december).{1,20}\\d{1,2}\"\n",
        "        ]\n",
        "\n",
        "        history_fragments = []\n",
        "\n",
        "        # Extract time-related information\n",
        "        for pattern in time_patterns:\n",
        "            matches = re.findall(pattern, patient_text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                history_fragments.extend(matches)\n",
        "\n",
        "        # Extract symptom descriptions with surrounding context\n",
        "        symptoms = entities.get(\"SYMPTOM\", [])\n",
        "        for symptom in symptoms:\n",
        "            pattern = r\"[^.!?]*(?:\" + re.escape(symptom) + r\")[^.!?]*[.!?]\"\n",
        "            symptom_contexts = re.findall(pattern, patient_text, re.IGNORECASE)\n",
        "            if symptom_contexts:\n",
        "                history_fragments.extend(symptom_contexts[:1])  # Just take the first mention\n",
        "\n",
        "        # If we have enough fragments, create a coherent history\n",
        "        if history_fragments:\n",
        "            history = \" \".join(history_fragments[:3])  # Limit to first 3 fragments\n",
        "            return history\n",
        "\n",
        "        # Fallback: create a basic history\n",
        "        diagnoses = entities.get(\"DIAGNOSIS\", [])\n",
        "        symptoms = entities.get(\"SYMPTOM\", [])\n",
        "\n",
        "        if diagnoses or symptoms:\n",
        "            history = f\"Patient reports \"\n",
        "            if symptoms:\n",
        "                history += f\"{', '.join(symptoms[:3])}\"\n",
        "                if diagnoses:\n",
        "                    history += \" with \"\n",
        "            if diagnoses:\n",
        "                history += f\"{', '.join(diagnoses[:2])}\"\n",
        "            return history\n",
        "\n",
        "        return \"Limited history available from conversation\"\n",
        "\n",
        "    def _extract_physical_exam(self, conversation_data):\n",
        "        \"\"\"Extract physical examination details\"\"\"\n",
        "        # Check if metadata contains examination info\n",
        "        exam_text = conversation_data.get(\"metadata\", {}).get(\"physical_examination\", \"\")\n",
        "        if exam_text:\n",
        "            return exam_text\n",
        "\n",
        "        # Look for examination description in physician statements\n",
        "        physician_statements = conversation_data.get(\"physician_statements\", [])\n",
        "        exam_indicators = [\"examine\", \"examination\", \"physical\", \"test\", \"testing\",\n",
        "                         \"check\", \"checked\", \"assess\", \"evaluated\", \"normal\", \"abnormal\"]\n",
        "\n",
        "        for statement in physician_statements:\n",
        "            if any(indicator in statement.lower() for indicator in exam_indicators):\n",
        "                return statement\n",
        "\n",
        "        return \"No detailed physical examination noted\"\n",
        "\n",
        "    def _determine_severity(self, entities, conversation_data):\n",
        "        \"\"\"Determine the severity of the condition\"\"\"\n",
        "        patient_text = conversation_data.get(\"all_patient_text\", \"\").lower()\n",
        "\n",
        "        # Look for severity indicators\n",
        "        severe_indicators = [\"severe\", \"extreme\", \"terrible\", \"worst\", \"unbearable\", \"excruciating\"]\n",
        "        moderate_indicators = [\"moderate\", \"significant\", \"considerable\", \"noticeable\"]\n",
        "        mild_indicators = [\"mild\", \"slight\", \"minor\", \"little\", \"improving\", \"better\"]\n",
        "\n",
        "        if any(indicator in patient_text for indicator in severe_indicators):\n",
        "            return \"Severe\"\n",
        "        elif any(indicator in patient_text for indicator in moderate_indicators):\n",
        "            return \"Moderate\"\n",
        "        elif any(indicator in patient_text for indicator in mild_indicators):\n",
        "            return \"Mild, improving\"\n",
        "\n",
        "        return \"Moderate\"\n",
        "\n",
        "    def _formulate_treatment_plan(self, entities, conversation_data):\n",
        "        \"\"\"Formulate treatment plan based on entities and conversation\"\"\"\n",
        "        treatments = entities.get(\"TREATMENT\", [])\n",
        "        physician_text = conversation_data.get(\"all_physician_text\", \"\").lower()\n",
        "\n",
        "        # Look for treatment recommendations\n",
        "        treatment_plan = []\n",
        "        if treatments:\n",
        "            treatment_plan.extend(treatments)\n",
        "\n",
        "        # Look for follow-up instructions\n",
        "        follow_up = \"Return for follow-up as needed\"\n",
        "        follow_up_patterns = [\n",
        "            r\"(?:come back|return|follow.up|see me).{1,50}(?:if|when|in case)\",\n",
        "            r\"(?:schedule|make).{1,30}(?:appointment|visit|follow.up)\"\n",
        "        ]\n",
        "\n",
        "        for pattern in follow_up_patterns:\n",
        "            matches = re.findall(pattern, physician_text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                follow_up = matches[0]\n",
        "                break\n",
        "\n",
        "        return {\n",
        "            \"Treatment\": \", \".join(treatment_plan) if treatment_plan else \"Continue current treatment regimen\",\n",
        "            \"Follow_Up\": follow_up\n",
        "        }\n",
        "\n",
        "    def generate_soap_note(self, conversation_data):\n",
        "        \"\"\"Generate a SOAP note from conversation data\"\"\"\n",
        "        # Extract entities first\n",
        "        entities = self.entity_recognizer.identify_entities(\n",
        "            conversation_data.get(\"all_patient_text\", \"\") + \" \" +\n",
        "            conversation_data.get(\"all_physician_text\", \"\")\n",
        "        )\n",
        "\n",
        "        # Extract components\n",
        "        chief_complaint = self._extract_chief_complaint(entities, conversation_data)\n",
        "        history = self._extract_history(conversation_data, entities)\n",
        "        physical_exam = self._extract_physical_exam(conversation_data)\n",
        "        severity = self._determine_severity(entities, conversation_data)\n",
        "        treatment_plan = self._formulate_treatment_plan(entities, conversation_data)\n",
        "\n",
        "        # Determine diagnosis\n",
        "        diagnoses = entities.get(\"DIAGNOSIS\", [])\n",
        "        diagnosis = \", \".join(diagnoses) if diagnoses else \"Assessment pending further evaluation\"\n",
        "\n",
        "        # Create structured SOAP note\n",
        "        soap_note = {\n",
        "            \"Subjective\": {\n",
        "                \"Chief_Complaint\": chief_complaint,\n",
        "                \"History_of_Present_Illness\": history\n",
        "            },\n",
        "            \"Objective\": {\n",
        "                \"Physical_Exam\": physical_exam,\n",
        "                \"Observations\": \"Based on patient report and examination\"\n",
        "            },\n",
        "            \"Assessment\": {\n",
        "                \"Diagnosis\": diagnosis,\n",
        "                \"Severity\": severity\n",
        "            },\n",
        "            \"Plan\": {\n",
        "                \"Treatment\": treatment_plan[\"Treatment\"],\n",
        "                \"Follow_Up\": treatment_plan[\"Follow_Up\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return soap_note"
      ],
      "metadata": {
        "id": "WgqsJLAZlIjv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete Pipeline"
      ],
      "metadata": {
        "id": "vZzJjw0XQMPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalNLPPipeline:\n",
        "    \"\"\"\n",
        "    Complete end-to-end pipeline for medical conversation analysis\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.parser = ConversationParser()\n",
        "        self.entity_recognizer = MedicalEntityRecognizer()\n",
        "        self.report_generator = MedicalReportGenerator(self.entity_recognizer)\n",
        "        self.sentiment_analyzer = MedicalSentimentAnalyzer()\n",
        "        self.soap_generator = SOAPNoteGenerator(self.entity_recognizer)\n",
        "\n",
        "    def process(self, conversation):\n",
        "        \"\"\"\n",
        "        Process a conversation through the complete pipeline\n",
        "        \"\"\"\n",
        "        # Step 1: Parse the conversation\n",
        "        conversation_data = self.parser.parse(conversation)\n",
        "\n",
        "        # Step 2: Extract medical entities\n",
        "        entities = self.entity_recognizer.identify_entities(\n",
        "            conversation_data.get(\"all_patient_text\", \"\") + \" \" +\n",
        "            conversation_data.get(\"all_physician_text\", \"\")\n",
        "        )\n",
        "\n",
        "        # Step 3: Generate medical report\n",
        "        report = self.report_generator.generate_report(conversation_data)\n",
        "\n",
        "        # Step 4: Analyze sentiment and intent\n",
        "        sentiment_analysis = self.sentiment_analyzer.analyze_conversation(conversation_data)\n",
        "\n",
        "        # Step 5: Generate SOAP note\n",
        "        soap_note = self.soap_generator.generate_soap_note(conversation_data)\n",
        "\n",
        "        # Combine all results into a comprehensive analysis\n",
        "        analysis = {\n",
        "            \"conversation_data\": conversation_data,\n",
        "            \"entities\": entities,\n",
        "            \"report\": report,\n",
        "            \"sentiment_analysis\": sentiment_analysis,\n",
        "            \"soap_note\": soap_note\n",
        "        }\n",
        "\n",
        "        return analysis\n",
        "\n",
        "    def generate_json_output(self, analysis):\n",
        "        \"\"\"\n",
        "        Generate a JSON representation of the analysis\n",
        "        \"\"\"\n",
        "        return json.dumps(analysis, indent=2)"
      ],
      "metadata": {
        "id": "dE_olljOlOYY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_pipeline():\n",
        "    \"\"\"\n",
        "    Test the pipeline with a sample conversation\n",
        "    \"\"\"\n",
        "    # Sample conversation\n",
        "    sample_conversation = \"\"\"\n",
        "    Physician: Good morning. How are you feeling today?\n",
        "\n",
        "    Patient: Not so great, doctor. My back has been killing me for the past two weeks after that car accident.\n",
        "\n",
        "    Physician: I'm sorry to hear that. Can you describe the pain?\n",
        "\n",
        "    Patient: It's a sharp pain in my lower back, especially when I try to bend over or get up from sitting. It's been getting slightly better over the last few days but still bothers me a lot.\n",
        "\n",
        "    Physician: And any other symptoms along with the back pain?\n",
        "\n",
        "    Patient: Sometimes I feel a tingling sensation down my left leg, and I've been having trouble sleeping because I can't find a comfortable position.\n",
        "\n",
        "    Physician: [Physician examines the patient's back, checking for tenderness and mobility] I notice you have some inflammation and tenderness in the lumbar region.\n",
        "\n",
        "    Physician: Based on your symptoms and the examination, you're experiencing lumbar strain from the accident. The tingling suggests some nerve irritation as well.\n",
        "\n",
        "    Patient: Is this serious? Will I need surgery?\n",
        "\n",
        "    Physician: No, I don't think surgery is necessary. This type of injury typically responds well to conservative treatment. I'm going to prescribe you some anti-inflammatory medication and muscle relaxants for the pain.\n",
        "\n",
        "    Patient: That's a relief. How long until I feel better?\n",
        "\n",
        "    Physician: Most people see significant improvement within 2-4 weeks with proper treatment. I'd also recommend some gentle stretching exercises and applying heat to the area. Would you like me to refer you to a physical therapist?\n",
        "\n",
        "    Patient: Yes, I think that would be helpful.\n",
        "\n",
        "    Physician: Great. I'll make that referral today. Take the medication as prescribed, and let's schedule a follow-up appointment in two weeks to see how you're progressing.\n",
        "\n",
        "    Patient: Thank you doctor, I'm feeling more hopeful now.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize and run the pipeline\n",
        "    pipeline = MedicalNLPPipeline()\n",
        "    analysis = pipeline.process(sample_conversation)\n",
        "\n",
        "    # Print the results\n",
        "    print(\"\\n===== CONVERSATION PARSING =====\")\n",
        "    print(f\"Patient name: {analysis['conversation_data']['metadata']['patient_name']}\")\n",
        "    print(f\"Number of physician statements: {len(analysis['conversation_data']['physician_statements'])}\")\n",
        "    print(f\"Number of patient statements: {len(analysis['conversation_data']['patient_statements'])}\")\n",
        "\n",
        "    print(\"\\n===== EXTRACTED ENTITIES =====\")\n",
        "    for category, entities in analysis['entities'].items():\n",
        "        print(f\"{category}: {', '.join(entities)}\")\n",
        "\n",
        "    print(\"\\n===== MEDICAL REPORT =====\")\n",
        "    for key, value in analysis['report'].items():\n",
        "        if isinstance(value, list):\n",
        "            print(f\"{key}: {', '.join(value)}\")\n",
        "        else:\n",
        "            print(f\"{key}: {value}\")\n",
        "\n",
        "    print(\"\\n===== SENTIMENT ANALYSIS =====\")\n",
        "    print(f\"Overall Sentiment: {analysis['sentiment_analysis']['Overall_Sentiment']}\")\n",
        "    print(f\"Primary Intent: {analysis['sentiment_analysis']['Primary_Intent']}\")\n",
        "    print(f\"Sentiment Progression: {analysis['sentiment_analysis']['Sentiment_Progression']}\")\n",
        "\n",
        "    print(\"\\n===== SOAP NOTE =====\")\n",
        "    print(\"Subjective:\")\n",
        "    for key, value in analysis['soap_note']['Subjective'].items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    print(\"Objective:\")\n",
        "    for key, value in analysis['soap_note']['Objective'].items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    print(\"Assessment:\")\n",
        "    for key, value in analysis['soap_note']['Assessment'].items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    print(\"Plan:\")\n",
        "    for key, value in analysis['soap_note']['Plan'].items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    return analysis\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to demonstrate pipeline usage\n",
        "    \"\"\"\n",
        "    print(\"Medical Transcription NLP Pipeline\")\n",
        "    print(\"==================================\")\n",
        "\n",
        "    # Test the pipeline\n",
        "    analysis = test_pipeline()\n",
        "\n",
        "    with open('analysis_results.json', 'w') as f:\n",
        "      json.dump(analysis, f, indent=2)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcVGl7VvV0Df",
        "outputId": "5efe39ea-16eb-4eb9-9c8c-606d57657a42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medical Transcription NLP Pipeline\n",
            "==================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== CONVERSATION PARSING =====\n",
            "Patient name: Unknown Patient\n",
            "Number of physician statements: 8\n",
            "Number of patient statements: 7\n",
            "\n",
            "===== EXTRACTED ENTITIES =====\n",
            "DIAGNOSIS: re experiencing lumbar strain from the accident, you have some inflammation and tenderness in, this type of injury typically responds well, after that car accident\n",
            "SYMPTOM: been having trouble sleeping because i can, ve been having trouble sleeping because i, i feel a tingling sensation down my, the tingling suggests some nerve, s a sharp pain in my lower, relaxants for the pain, you describe the pain, with the back pain\n",
            "PROGNOSIS: been getting slightly better over the last, people see significant improve, most people see sign, until i feel better, re progress\n",
            "TREATMENT: inflammatory medication and muscle relaxants, take the medication as prescribed, some gentle stretching exercise, well to conservative treatment, t think surgery is necessary, weeks with proper treatment, will i need surgery\n",
            "\n",
            "===== MEDICAL REPORT =====\n",
            "Patient_Name: Unknown Patient\n",
            "Symptoms: been having trouble sleeping because i can, ve been having trouble sleeping because i, i feel a tingling sensation down my, s a sharp pain in my lower, the tingling suggests some nerve, relaxants for the pain, you describe the pain, with the back pain\n",
            "Diagnosis: after that car accident, re experiencing lumbar strain from the accident, you have some inflammation and tenderness in, this type of injury typically responds well\n",
            "Treatment: will i need surgery, inflammatory medication and muscle relaxants, take the medication as prescribed, some gentle stretching exercise, well to conservative treatment, t think surgery is necessary, weeks with proper treatment\n",
            "Current_Status: feeling more hopeful now\n",
            "Prognosis: Condition expected to improve\n",
            "\n",
            "===== SENTIMENT ANALYSIS =====\n",
            "Overall Sentiment: Reassured\n",
            "Primary Intent: Seeking reassurance\n",
            "Sentiment Progression: Stable (Reassured)\n",
            "\n",
            "===== SOAP NOTE =====\n",
            "Subjective:\n",
            "  Chief_Complaint: been having trouble sleeping because i can, ve been having trouble sleeping because i\n",
            "  History_of_Present_Illness: for the past two weeks  Sometimes I feel a tingling sensation down my left leg, and I've been having trouble sleeping because I can't find a comfortable position.  Sometimes I feel a tingling sensation down my left leg, and I've been having trouble sleeping because I can't find a comfortable position.\n",
            "Objective:\n",
            "  Physical_Exam: Physician examines the patient's back, checking for tenderness and mobility\n",
            "  Observations: Based on patient report and examination\n",
            "Assessment:\n",
            "  Diagnosis: re experiencing lumbar strain from the accident, you have some inflammation and tenderness in, this type of injury typically responds well, after that car accident\n",
            "  Severity: Mild, improving\n",
            "Plan:\n",
            "  Treatment: inflammatory medication and muscle relaxants, take the medication as prescribed, some gentle stretching exercise, well to conservative treatment, t think surgery is necessary, weeks with proper treatment, will i need surgery\n",
            "  Follow_Up: schedule a follow-up appointment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nbe8T58lXXun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Some sample conversations to test the application with\n",
        "\n",
        "#conversation 1:\n",
        "\"\"\"\n",
        "  Physician: Good afternoon, Mr. Patel. How have your blood sugar levels been recently?\n",
        "  Patient: Good afternoon, doctor. They've been mostly stable, but I had a few spikes last week.\n",
        "  Physician: I see. Do you remember what might have triggered those spikes?\n",
        "  Patient: I think it was after a couple of big meals. I attended a family gathering, and I had some sweets.\n",
        "  Physician: That makes sense. Managing portion sizes and carbohydrate intake is key. Are you still taking your medications as prescribed?\n",
        "  Patient: Yes, I take my metformin daily. I also check my blood sugar every morning before breakfast.\n",
        "  Physician: That’s great. Have you experienced any symptoms like dizziness, excessive thirst, or fatigue?\n",
        "  Patient: No, not really. I feel fine most of the time.\n",
        "  Physician: That’s good to hear. Let’s review your latest blood test results. Your HbA1c is at 6.8%, which is slightly above target. I’d recommend adjusting your diet slightly and incorporating a bit more physical activity.\n",
        "  Patient: Okay, I’ll try to be more mindful of that.\n",
        "  Physician: Excellent. Let’s schedule a follow-up in three months to reassess your progress. In the meantime, if you notice any significant changes, please reach out.\n",
        "\"\"\"\n",
        "\n",
        "#conversation 2:\n",
        "\"\"\"\n",
        "  Physician: Hello, Mrs. Lopez. How is little Daniel doing today?\n",
        "  Parent: Hi, doctor. He’s doing well, but he’s had a bit of a cough the past few days.\n",
        "  Physician: I see. Has he had any fever or difficulty breathing?\n",
        "  Parent: No fever, but he’s been a little more tired than usual.\n",
        "  Physician: That’s important to note. Is he eating and drinking normally?\n",
        "  Parent: Yes, he’s eating fine, but he doesn’t have much of an appetite in the mornings.\n",
        "  Physician: That’s common with mild respiratory infections. Let me listen to his lungs.\n",
        "  [Physical Examination Conducted]\n",
        "  Physician: His lungs sound clear, and there are no signs of anything serious. It looks like a mild viral infection. Make sure he gets plenty of fluids and rest.\n",
        "  Parent: That’s a relief. Should I give him any medicine?\n",
        "  Physician: If his cough worsens or he develops a fever, you can give him children's paracetamol. Otherwise, warm fluids and a humidifier at night can help.\n",
        "  Parent: Got it. Thank you, doctor.\n",
        "  Physician: You’re welcome! If the cough persists for more than ten days or gets worse, come back for a re-evaluation.\n",
        "\"\"\"\n",
        "\n",
        "#conversation 3:\n",
        "\"\"\"\n",
        "    Physician: Good morning, Mr. Carter. How are you feeling since your knee surgery?\n",
        "    Patient: Good morning, doctor. It’s been a bit sore, but I think I’m healing well.\n",
        "    Physician: That’s normal. Are you still using crutches?\n",
        "    Patient: Yes, but only when I need to walk long distances. Around the house, I manage without them.\n",
        "    Physician: That’s good progress. Have you noticed any swelling or unusual pain?\n",
        "    Patient: The swelling has gone down a lot, and the pain is manageable with the medication.\n",
        "    Physician: Excellent. Have you started physiotherapy?\n",
        "    Patient: Yes, I had my first session last week. It was tough, but I can already feel an improvement in my movement.\n",
        "    Physician: That’s great to hear. Keep up with the exercises—they’re key to your full recovery. I expect you’ll be able to walk normally without crutches in about three more weeks.\n",
        "    Patient: That’s good news! Anything else I should watch for?\n",
        "    Physician: Just be mindful of any redness, warmth, or increased pain around the incision site—those could be signs of infection. If that happens, let me know immediately.\n",
        "    Patient: Will do. Thanks, doctor.\n",
        "    Physician: You’re very welcome, Mr. Carter. Keep up the good work!\n",
        "\"\"\"\n",
        "\n",
        "#just paste these in place of the sample conversation to test the application\n",
        "\n",
        "#also check out the json file created by the app"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "collapsed": true,
        "id": "UXhC9ON4XSVN",
        "outputId": "2c8b6a98-e695-4949-d7b4-c689548cdde1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    Physician: Good morning, Mr. Carter. How are you feeling since your knee surgery?\\n    Patient: Good morning, doctor. It’s been a bit sore, but I think I’m healing well.\\n    Physician: That’s normal. Are you still using crutches?\\n    Patient: Yes, but only when I need to walk long distances. Around the house, I manage without them.\\n    Physician: That’s good progress. Have you noticed any swelling or unusual pain?\\n    Patient: The swelling has gone down a lot, and the pain is manageable with the medication.\\n    Physician: Excellent. Have you started physiotherapy?\\n    Patient: Yes, I had my first session last week. It was tough, but I can already feel an improvement in my movement.\\n    Physician: That’s great to hear. Keep up with the exercises—they’re key to your full recovery. I expect you’ll be able to walk normally without crutches in about three more weeks.\\n    Patient: That’s good news! Anything else I should watch for?\\n    Physician: Just be mindful of any redness, warmth, or increased pain around the incision site—those could be signs of infection. If that happens, let me know immediately.\\n    Patient: Will do. Thanks, doctor.\\n    Physician: You’re very welcome, Mr. Carter. Keep up the good work!\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}